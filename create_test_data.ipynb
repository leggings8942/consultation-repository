{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from dotenv import load_dotenv\n",
    "import random, string\n",
    "\n",
    "import pyspark as ps\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_conf = ps.SparkConf()\\\n",
    "            .set(\"spark.sql.sources.commitProtocolClass\", \"org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol\")\\\n",
    "            .set(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\", \"false\")\\\n",
    "            .set(\"spark.sql.shuffle.partitions\", 100)\\\n",
    "            .set(\"spark.sql.dynamicPartitionPruning.enabled\", True)\n",
    "            # '_started'と'_committed_'で始まるファイルを書き込まないように設定\n",
    "            # '_SUCCESS'で始まるファイルを書き込まないように設定\n",
    "            # パーティション数を調整する\n",
    "            # 動的パーティションプルーニングの有効化\n",
    "spark = SparkSession.builder.config(conf=ps_conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(join(os.getcwd(), '.env'))\n",
    "BASE_PATH     = os.environ.get(\"BASE_PATH\")\n",
    "WORK_PATH     = BASE_PATH + os.environ.get(\"WORK_PATH\")\n",
    "PROJECT_NAME  = os.environ.get(\"PROJECT_NAME\")\n",
    "INSTRUCT_PATH = WORK_PATH + PROJECT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回遊1階層のテストデータ生成\n",
    "\n",
    "# 75端末、24時間分\n",
    "unit_terminal = 75\n",
    "unit_id_num   = unit_terminal * 24\n",
    "\n",
    "random_unit_list = [''.join(random.choices(string.digits, k=5)) for _ in range(0, unit_id_num)]\n",
    "tmp_list = [[unit_id, random.random()] for unit_id in random_unit_list]\n",
    "\n",
    "df_schema = types.StructType([\n",
    "        types.StructField('ORIGIN',      types.StringType(), False),\n",
    "        types.StructField('移動影響量',    types.FloatType(),  False),\n",
    "    ])\n",
    "df_migrate1 = spark.createDataFrame(tmp_list, df_schema)\n",
    "df_migrate1\\\n",
    "\t.orderBy(col('ORIGIN').asc())\\\n",
    "    .toPandas()\\\n",
    "    .to_csv(INSTRUCT_PATH + 'csv_data/test_tmp.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回遊2階層のテストデータ生成\n",
    "\n",
    "df_schema = types.StructType([\n",
    "        types.StructField('ORIGIN',      types.StringType(), False),\n",
    "        types.StructField('DESTINATION', types.StringType(), False),\n",
    "        types.StructField('移動影響量',    types.FloatType(),  False),\n",
    "    ])\n",
    "df_migrate2 = spark.createDataFrame([], df_schema)\n",
    "\n",
    "print(\"回遊1階層 一時保管開始\")\n",
    "df_migrate1.persist(StorageLevel.MEMORY_ONLY)\n",
    "df_migrate1.count()\n",
    "print(\"回遊1階層 一時保管終了\")\n",
    "\n",
    "for unit_id, move in tmp_list:\n",
    "    df_tmp      = df_migrate1\\\n",
    "        \t\t\t\t.withColumn('DESTINATION', F.lit(unit_id))\\\n",
    "\t\t\t\t\t\t.withColumn('移動影響量',    col('移動影響量') * move)\n",
    "    df_migrate2 = df_migrate2.unionByName(df_tmp)\n",
    "\n",
    "print(\"回遊2階層 計算開始\")\n",
    "df_migrate2.persist(StorageLevel.MEMORY_ONLY)\n",
    "df_migrate2.count()\n",
    "print(\"回遊2階層 計算終了\")\n",
    "\n",
    "df_migrate2\\\n",
    "    .orderBy(col('ORIGIN').asc(), col('DESTINATION').asc())\\\n",
    "    .toPandas()\\\n",
    "    .to_csv(INSTRUCT_PATH + f'csv_data/test_terminal{unit_terminal}.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
